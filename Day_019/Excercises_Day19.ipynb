{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 19"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Level 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Excercise 1a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of lines in obama_speech.txt file is:  66\n",
      "The number of words in obama_speech.txt file is:  2400\n"
     ]
    }
   ],
   "source": [
    "# Read obama_speech.txt file and count number of lines and words\n",
    "\n",
    "with open (r'C:\\Users\\This Pc\\Desktop\\Arewa Datascience\\files\\obama_speech.txt') as f:\n",
    "    #Lets get a list of the lines first and then count them\n",
    "    lines=f.readlines()\n",
    "    no_of_lines=len(lines)\n",
    "    print('The number of lines in obama_speech.txt file is: ',no_of_lines)\n",
    "\n",
    "    \n",
    "with open (r'C:\\Users\\This Pc\\Desktop\\Arewa Datascience\\files\\obama_speech.txt') as f:\n",
    "    # Let's read the whole text split it to list of words and then count them\n",
    "     txt=f.read()\n",
    "     words=txt.split()\n",
    "     no_of_words=len(words)\n",
    "     print('The number of words in obama_speech.txt file is: ',no_of_words)\n",
    "   \n",
    "\n",
    "  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Excercise 1b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of lines in michelle_obama_speech.txt file is:  83\n",
      "The number of words in michelle_obama_speech.txt file is:  2204\n"
     ]
    }
   ],
   "source": [
    "# Read michelle_obama_speech.txt file and count number of lines and words\n",
    "\n",
    "with open (r'C:\\Users\\This Pc\\Desktop\\Arewa Datascience\\files\\michelle_obama_speech.txt') as f:\n",
    "    #Lets get a list of the lines first and then count them\n",
    "    lines=f.readlines()\n",
    "    no_of_lines=len(lines)\n",
    "    print('The number of lines in michelle_obama_speech.txt file is: ',no_of_lines)\n",
    "\n",
    "    \n",
    "with open (r'C:\\Users\\This Pc\\Desktop\\Arewa Datascience\\files\\michelle_obama_speech.txt') as f:\n",
    "    # Let's read the whole text split it to list of words and then count them\n",
    "     txt=f.read()\n",
    "     words=txt.split()\n",
    "     no_of_words=len(words)\n",
    "     print('The number of words in michelle_obama_speech.txt file is: ',no_of_words)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Excercise 1c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of lines in donald_speech.txt file is:  48\n",
      "The number of words in donald_speech.txt file is:  1259\n"
     ]
    }
   ],
   "source": [
    "# Read donald_speech.txt file and count number of lines and words\n",
    "\n",
    "with open (r'C:\\Users\\This Pc\\Desktop\\Arewa Datascience\\files\\donald_speech.txt') as f:\n",
    "    #Lets get a list of the lines first and then count them\n",
    "    lines=f.readlines()\n",
    "    no_of_lines=len(lines)\n",
    "    print('The number of lines in donald_speech.txt file is: ',no_of_lines)\n",
    "\n",
    "    \n",
    "with open (r'C:\\Users\\This Pc\\Desktop\\Arewa Datascience\\files\\donald_speech.txt') as f:\n",
    "    # Let's read the whole text split it to list of words and then count them\n",
    "     txt=f.read()\n",
    "     words=txt.split()\n",
    "     no_of_words=len(words)\n",
    "     print('The number of words in donald_speech.txt file is: ',no_of_words)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Excecise 1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of lines in melina_trump_speech.txt file is:  33\n",
      "The number of words in melina_trump_speech.txt file is:  1375\n"
     ]
    }
   ],
   "source": [
    "# Read melina_trump_speech.txt file and count number of lines and words\n",
    "\n",
    "with open (r'C:\\Users\\This Pc\\Desktop\\Arewa Datascience\\files\\melina_trump_speech.txt') as f:\n",
    "    #Lets get a list of the lines first and then count them\n",
    "    lines=f.readlines()\n",
    "    no_of_lines=len(lines)\n",
    "    print('The number of lines in melina_trump_speech.txt file is: ',no_of_lines)\n",
    "\n",
    "    \n",
    "with open (r'C:\\Users\\This Pc\\Desktop\\Arewa Datascience\\files\\melina_trump_speech.txt') as f:\n",
    "    # Let's read the whole text split it to list of words and then count them\n",
    "     txt=f.read()\n",
    "     words=txt.split()\n",
    "     no_of_words=len(words)\n",
    "     print('The number of words in melina_trump_speech.txt file is: ',no_of_words)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Excercise 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('English', 91),\n",
       " ('French', 45),\n",
       " ('Arabic', 25),\n",
       " ('Spanish', 24),\n",
       " ('Portuguese', 9),\n",
       " ('Russian', 9),\n",
       " ('Dutch', 8),\n",
       " ('German', 7),\n",
       " ('Chinese', 5),\n",
       " ('Serbian', 4)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the countries_data.json data file in data directory,\n",
    "# create a function that finds the ten most spoken languages\n",
    "\n",
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "def most_spoken_languages(file_path,k):\n",
    "\n",
    "    # Let's read the json file\n",
    "    with open (file_path, encoding=\"utf8\") as f:\n",
    "        #Lets convert the json list to list of dicts\n",
    "        lst_of_dct=json.load(f)\n",
    "        # Lets iterate through the list and get list of languages\n",
    "        list_of_langs=[]\n",
    "        for country in lst_of_dct:\n",
    "            list_of_langs.append(tuple(country['languages']))\n",
    "\n",
    "        #Converting list of tuples to a plain list\n",
    "        plain_list = [language for tpl in list_of_langs for language in tpl]\n",
    "\n",
    "        #Let's count the most spoken languages\n",
    "        counter=Counter(plain_list)\n",
    "        most_spoken=counter.most_common(k)\n",
    "\n",
    "    return most_spoken\n",
    "\n",
    "# Let's the function\n",
    "most_spoken_languages(r'C:\\Users\\This Pc\\Desktop\\Arewa Datascience\\files\\countries_data.json', 10)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a6c3004ce060ded9e0c076ab48db6d8cf68670c15173d9367e97ef3f186c9ed1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
